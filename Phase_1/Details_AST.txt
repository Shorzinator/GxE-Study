1. Distribution of raw data
    Before balancing -
    Rows before balancing: 16427
    AntisocialTrajectory
    4.0    0.788702
    2.0    0.123090
    3.0    0.069641
    1.0    0.018567

    After balancing -
    Rows after balancing: 51824
    AntisocialTrajectory
    4.0    0.25
    2.0    0.25
    3.0    0.25
    1.0    0.25

2. Missing values count:
    ID                            0
    FamilyID                  10771
    Race                         41
    PolygenicScoreEXT         10771
    Sex                           2
    Age                          17
    DelinquentPeer              135
    SchoolConnect                92
    NeighborConnect             103
    ParentalWarmth              445
    AntisocialTrajectory        106
    SubstanceUseTrajectory      106

3. Rows before handling outliers: 20745. Rows after: 20640.

4. Rows before dropping missing values in target: 20640. Rows after: 20534.

5. Results after the first run of the code
    Training Metrics:
    - Model: logistic_regression
    - Classification Type: Multinomial
    - Overall Accuracy: 0.4539 (or 45.39%)

    For class "1":
    - Precision: 0.4750 (or 47.50%)
    - Recall: 0.6186 (or 61.86%)
    - F1-Score: 0.5374 (or 53.74%)

    For class "2":
    - Precision: 0.3603 (or 36.03%)
    - Recall: 0.3900 (or 39.00%)
    - F1-Score: 0.3746 (or 37.46%)

    For class "3":
    - Precision: 0.3833 (or 38.33%)
    - Recall: 0.2059 (or 20.59%)
    - F1-Score: 0.2679 (or 26.79%)

    For class "4":
    - Precision: 0.5578 (or 55.78%)
    - Recall: 0.6013 (or 60.13%)
    - F1-Score: 0.5787 (or 57.87%)

    The macro and weighted averages for precision, recall, and F1-score are also provided.

    Testing Metrics:
    - Model: logistic_regression
    - Classification Type: Multinomial
    - Overall Accuracy: 0.5330 (or 53.30%)

    For class "1":
    - Precision: 0.0883 (or 8.83%)
    - Recall: 0.6184 (or 61.84%)
    - F1-Score: 0.1546 (or 15.46%)

    For class "2":
    - Precision: 0.1672 (or 16.72%)
    - Recall: 0.3399 (or 33.99%)
    - F1-Score: 0.2241 (or 22.41%)

    For class "3":
    - Precision: 0.1429 (or 14.29%)
    - Recall: 0.2133 (or 21.33%)
    - F1-Score: 0.1711 (or 17.11%)

    For class "4":
    - Precision: 0.9009 (or 90.09%)
    - Recall: 0.5894 (or 58.94%)
    - F1-Score: 0.7126 (or 71.26%)

    Again, the macro and weighted averages for precision, recall, and F1-score are provided.

    Analysis:
    1. For the training set, the model seems to be doing the best in predicting class "4" and worst in predicting class "3".
    2. In the testing set, the precision for class "1" is surprisingly low at 8.83%, while it has a high recall of 61.84%. This indicates that the model is identifying a lot of instances as class "1", but a large portion of them are false positives.
    3. For class "4" in the testing set, the precision is very high (90.09%), indicating that when the model predicts class "4", it's often correct.
    4. The overall accuracy for training and testing is 45.39% and 53.30%, respectively. While these aren't extremely high values, they do suggest the model has learned some patterns in the data.

    To improve the model, consider fine-tuning, using more features if available, or trying different models altogether.

